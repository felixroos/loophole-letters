---
title: Real Time Synthesis
description: Without pregenerating Buffers
date: "2023-09-20"
tags: ["code"]
draft: true
---

import { BufferPlayer2 } from "../../components/zzfx/BufferPlayer2.jsx";
import { BufferChain } from "../../components/buffers/BufferChain";

Last time, I was getting into generating buffers by hand to do synthesis.
This approach is good to learn the basics of sample manipulation, but one obvious limitation is that it does not run in real time,
as each buffer is pregenerated for a specified number of seconds and then played back.

<BufferPlayer2 value={`sin(t / 20)`} seconds={1} client:only />

It would be nice if we could repeatedly regenerate buffers to create endless streams of audio.

Let's solve this problem in a very naive way first..

## Temporal Recursion

First, we need an endless loop:

```js
function timesink(fn, duration = 1000) {
  let block = 0;
  function sink() {
    fn(block++) && setTimeout(sink, duration);
  }
  sink();
}
```

The above snippet implements a simple temporal recursion, where the function passed to timesink is called repeatedly.
When the function returns false, the recursion stops. This is just a more fancy way to do `setInterval`.
Let's use it:

```js
timesink((block) => {
  console.log("block", block);
  return block <= 5;
});
```

If you copy the above snippet, your console should log the block numbers accordingly..

## Buffer Chaining

Using the loop, we can then chain multple buffer together like this:

```js
document.addEventListener("click", function handleClick() {
  const ac = new AudioContext();
  const seconds = 1;
  const nSamples = seconds * ac.sampleRate;
  let t = 0;
  let playhead = 0;

  const buffer = ac.createBuffer(1, nSamples, ac.sampleRate);
  const samples = new Float32Array(nSamples);

  timesink((block) => {
    const getSample = () => Math.sin(++t / 20);
    for (let i = 0; i < samples.length; i++) {
      samples[i] = getSample(i); // call fn on each sample
    }
    // buffer.copyToChannel(samples, 0);
    buffer.getChannelData(0).set(samples);
    // play the buffer
    const source = ac.createBufferSource();
    source.buffer = buffer;
    source.connect(ac.destination);
    playhead < ac.currentTime && console.log("TOO LATE...");
    console.log("playhead", playhead);
    source.start(playhead);
    playhead += source.buffer.duration;
    return block < 10;
  }, seconds * 1000);
  document.removeEventListener("click", handleClick);
});
```

- The `t` variable counts the absolute sample number as time progresses
- The `playhead` variable makes sure the next buffer starts exactly where the last one left off.

If you let that run for a while, you might get `TOO LATE...` logged to the console, because the timeout clock is not synced to the audio context clock...

We **could** solve that problem by replacing `timesink` with the "Tale of 2 Clocks" scheduling mechanism from an earlier post:

<details>
<summary>show code</summary>

```js
// generalized "Tale of 2 Clocks" scheduling
function createClock(
  getTime,
  callback, // called slightly before each cycle
  duration = 0.05, // duration of each cycle
  interval = 0.1, // interval between callbacks
  overlap = 0.1 // overlap between callbacks
) {
  let tick = 0; // counts callbacks
  let phase = 0; // next callback time
  let precision = 10 ** 4; // used to round phase
  let minLatency = 0.01;
  const setDuration = (setter) => (duration = setter(duration));
  overlap = overlap || interval / 2;
  const onTick = () => {
    const t = getTime();
    const lookahead = t + interval + overlap; // the time window for this tick
    if (phase === 0) {
      phase = t + minLatency;
    }
    // callback as long as we're inside the lookahead
    while (phase < lookahead) {
      phase = Math.round(phase * precision) / precision;
      phase >= t && callback(phase, duration, tick);
      phase < t && console.log("TOO LATE", phase); // what if latency is added from outside?
      phase += duration; // increment phase by duration
      tick++;
    }
  };
  let intervalID;
  const start = () => {
    clear(); // just in case start was called more than once
    onTick();
    intervalID = setInterval(onTick, interval * 1000);
  };
  const clear = () => intervalID !== undefined && clearInterval(intervalID);
  const pause = () => clear();
  const stop = () => {
    tick = 0;
    phase = 0;
    clear();
  };
  const getPhase = () => phase;
  // setCallback
  return {
    setDuration,
    start,
    stop,
    pause,
    duration,
    interval,
    getPhase,
    minLatency,
  };
}

// clock specific for AudioContext
function getClock(ac, fn, interval) {
  const getTime = () => ac.currentTime;
  const clock = createClock(
    getTime,
    // called slightly before each cycle
    fn,
    interval // duration of each cycle
  );
  return clock;
}
```

</details>

Using the clock, we can chain buffers like this:

```js
function bufferclock(ac, fn) {
  let t = 0,
    playhead;
  const interval = 0.1;
  const nSamples = interval * ac.sampleRate;
  const buffer = ac.createBuffer(1, nSamples, ac.sampleRate);
  const samples = new Float32Array(nSamples);

  const clock = getClock(
    ac,
    () => {
      // fill buffer
      for (let i = 0; i < samples.length; i++) {
        samples[i] = fn(i); // call fn on each sample
      }
      buffer.getChannelData(0).set(samples);

      // play buffer
      const source = ac.createBufferSource();
      source.buffer = buffer;
      source.connect(ac.destination);
      playhead = playhead || ac.currentTime;
      playhead < ac.currentTime && console.log("OH NO...");
      source.start(playhead);
      playhead += source.buffer.duration;
      source.stop(playhead);
    },
    interval
  );
  return clock;
}
```

... and use it:

```js
document.addEventListener("click", function handleClick() {
  const ac = new AudioContext();
  let t = 0;
  const clock = bufferclock(ac, () => Math.sin(++t / 20));

  clock.start();
  setTimeout(() => {
    clock.stop();
  }, 10000);
  document.removeEventListener("click", handleClick);
});
```

Again, you can copy that to your console to hear 10 seconds of a hopefully crackle-free rising sine tone.

## Live Coding DSP

With the above implementation, we can already live code our DSP:

<BufferChain client:only value={`Math.sin(440*t*2*Math.PI/ac.sampleRate)`} />

Press ctrl+enter to update while it's playing!
This editor also supports the abstractions from the buffer post:

<BufferChain client:only value={`saw(330) + saw(440) + saw(550)`} />

## Bonus: Bytebeat

That editor can be used to play bytebeat / flotbeat:

<BufferChain
  client:only
  rows={4}
  value={`((
((t*("36364689"[t>>13&7]&15))/12&128)+(((((t>>12)^(t>>12)-2)%11*t)/4|t>>13)&127)
) & 255) / 127.5 - 1`}
/>
